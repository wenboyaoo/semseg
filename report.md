# 用 DINOv3 和 PSPNet 实现图像语义分割算法实验报告
## 一、实验目的

本实验的目的是使用 ConvNeXt 结构的 DINOv3 预训练模型作为特征提取网络，结合 PSPNet 的多尺度上下文聚合模块（Pyramid Pooling Module, PPM）构建高精度图像语义分割模型。

## 二、实验背景

### 1. DINOv3
arXiv:[2508.10104](https://arxiv.org/abs/2508.10104)

DINOv3 是 Meta AI 于 2025 年提出的自监督视觉表征学习模型，是 DINOv2 的延续。其核心目标是在无标签数据上学习高质量的通用视觉特征，使模型在下游任务（如分类、检测、语义分割）中无需微调或仅需极少微调即可获得优异性能。与前代相比，DINOv3 进一步提升了训练规模、模型结构与特征稳定性，提出了新型的 Gram Anchoring 正则机制，在保持全局语义一致性的同时，显著改善了密集预测任务中的局部特征质量。这一特性使其特别适合作为语义分割等任务的冻结特征提取骨干。

DINOv3 提供两种结构的模型：
1. ViT（Vision Transformer）：基于自注意力机制，具有全局建模能力。
2. ConvNeXt：一种卷积化的现代网络架构，保留卷积网络的空间归纳偏置，在中小尺度目标和结构化场景中表现更优。

本实验选择 ConvNeXt 结构的模型是因为：
1. PSPNet 主要是为 CNN 弥补感受野不足设计的，ViT 使用注意力机制，本身就有全局感受野
2. ConvNeXt 保留空间结构，适合进行“局部到全局”的池化。ViT 则将图像切成 patch 序列输入 transformer，输出 token 序列，空间不连续，不利于空间池化。

本次实验使用参数量最小的 DINOv3 ConvNeXt Tiny 模型，各隐藏层输出的通道数和输出步长：
| 层级 | 输入 | 隐藏层0 | 隐藏层1 | 隐藏层2 | 隐藏层3 |
|:----:|:-----:|:--------:|:--------:|:--------:|:--------:|
| 通道数 | 3 | 96 | 192 | 384 | 768 |
| 输出步长 (OS) | 1 | 4 | 8 | 16 | 32 |


### 2. PSPNet（Pyramid Scene Parsing Network）
arXiv:[1612.01105](https://arxiv.org/abs/1612.01105)

PSPNet 的核心思想是通过金字塔池化模块 PPM 聚合多尺度上下文信息，从而在保持局部细节的同时提升全局语义一致性。

PSPNet 的整体结构是以卷积神经网络（如 ResNet-50/101）为骨干，在其末端添加 PPM 模块以整合不同尺度的特征。PPM 通过在多个尺度上进行平均池化（常用 1×1、2×2、3×3、6×6 四个尺度），再经过卷积、归一化和激活得到多尺度特征，上采样回原尺寸并拼接，形成多尺度语义增强特征，最后通过分类头输出像素级预测。

在本实验中，PSPNet 被用于增强 DINOv3 卷积特征的多尺度上下文建模能力，弥补其有限的感受野。

### 3. FPN（Feature Pyramid Network）
arXiv:[1612.03144](https://arxiv.org/abs/1612.03144)

FPN 是一种用于多尺度特征融合的通用网络结构。在卷积神经网络中，不同层级的特征具有不同的语义深度与空间分辨率，FPN 通过自顶向下与横向连接（top-down + lateral connection）机制，将高语义、低分辨率的深层特征与低语义、高分辨率的浅层特征逐层融合，构建出层次化的特征金字塔。

在本实验中，FPN 被用于融合 DINOv3 不同阶段的特征输出（Stage 1–3），将原本输出步长 OS=32 的高层特征通过多尺度融合与上采样恢复至 OS=8，从而补充小目标细节，为 PSPNet 的金字塔池化模块提供更丰富的输入特征。

## 三、模型结构
### 1. 模型整体结构
最终选取的模型结构如下：
```
 PSPNet(
  backbone: DINOv3 ConvNeXt-tiny (冻结参数)
  fpn: Feature Pyramid Network (输出通道 1024, 输出 OS=8)
  ppm: Pyramid Pooling Module
  cls: 3×3 + 1×1 卷积分类头 (21类)
)
```
1. FPN模块：
- 接收 DINOv3 ConvNeXt 第 0～3 阶段输出；
- 统一通道维度至 1024；
- 输出特征的 OS=8，与原 PSPNet 一致。
2. PPM模块：
- 在 1×1、2×2、3×3、6×6 尺度上进行池化；
- 拼接后送入分类头。
3. 分类头（CLS Head）：
- 两层卷积（3×3 + 1×1），输出通道 21（PASCAL VOC 2012 类别数）。

### 2. 修改内容
对原PSPNet进行的主要修改：
1. 将特征提取网络替换为 DINOv3 并冻结全部参数
2. 使用 FPN 模块解决 DINOv3 特征图下采样过大（OS=32）导致的小物体信息丢失问题。
   
细节修改:
1. 将各层中上采样的 align_corners 改为 False 保证与 DINOv3 输入输出尺寸要求一致
2. 将输入尺寸裁剪改为 224×224 来与 DINOv3 预训练输入匹配，防止特征错位

## 四、实验内容
1. 数据集：PASCAL VOC 2012（21类，包括背景）
- 训练集：10582张
- 验证集：1449张
2. 训练设置
- batch_size: 32
- 损失函数: 交叉熵损失
- 优化器和学习策略:使用 SGD 优化器，初始学习率 0.01，动量 0.9，权重衰减 1e-4，采用多项式衰减 (power=0.9)
- 数据增强：随机缩放（0.5–2.0倍）和旋转（±10°）
- 训练轮数：50 epochs
3. 指标：mIoU、mAcc、allAcc
4. 比较方案：
- ResNet50 + PPM + 分类头（原PSPNet）
- ResNet50(恢复最后两个隐藏层中的下采样) + PPM + 分类头
- DINOv3 + 分类头
- DINOv3 + PPM + 分类头
- DINOv3 + FPN + 分类头
- DINOv3 + FPN + PPM + 分类头 (不同FPN输出通道数)

## 五、实验结果

| 序号 | 模型结构 | mIoU | mAcc | allAcc |
|:--: |:--:|:--:|:--:|:--:|
|1| ResNet50 + PPM + 分类头| 0.7705 | 0.8513 | 0.9489 |
|2| DINOv3 + 分类头 | 0.7599 | 0.8634 | 0.9427 |
|3| DINOv3 + PPM + 分类头 | 0.7630 | 0.8654 | 0.9430 |
|4| DINOv3 + FPN + 分类头 (FPN输出768通道) | 0.7870 | 0.8738 | 0.9530 |
|5| DINOv3 + FPN + PPM + 分类头 (FPN输出768通道) | 0.8156 | 0.8989 | 0.9591 |
|6| ResNet50 + PPM + 分类头 （复现）| 0.7641 | 0.8483 | 0.9476 |
|7| ResNet50 恢复下采样 + PPM + 分类头 | 0.7528 | 0.8361 | 0.9421 |
|8| DINOv3 + FPN + PPM + 分类头 (FPN输出512通道) | 0.8132 | 0.9028 | 0.9586 |
|9| **DINOv3 + FPN + PPM + 分类头 (FPN输出1024通道)** | **0.8162** | **0.9061** | **0.9595** |
|10| DINOv3 + FPN + PPM + 分类头 (FPN输出2048通道) | 0.8180| 0.9062 | 0.9597 |

## 六、结果分析

1. 在 DINOv3 后直接加入 PPM 对性能提升有限(结果2、3)，且相较于原始 PSPNet mIoU低、mAcc高，表明模型不能准确分辨小物体(结果1，3)。与原 PSPNet 对比、推测原因是 DINOv3 OS 过大，造成小物体消失，PPM中的池化尺度相较特征图太大，不利于上采样等，从而导致 PPM 效果弱、最终模型性能差。
2. 恢复原始 PSPNet 的下采样卷积，将 OS 从 8 提高到 32 后 mIoU 明显下降(结果6、7)，验证 1. 中猜测，推测可以通过降低 OS 提高模型性能。DINOv3 预训练强，本身被设计成可冻结使用的特征提取网络，修改结构后解冻训练难度高，因此使用 FPN 提高 OS。
3. 加入 FPN 后模型性能明显提高（结果3、5），且 PPM 可以有效提高性能(结果4、5)，说明改进有效，且 PPM 高 OS 的瓶颈被解除。
4. 提高 FPN 输出通道数可以提高模型性能(结果8、5、9、10)，但参数量和计算开销随通道数上升。在实验选取的通道数中，1024通道后性能提升不明显，因此选择1024通道。

## 七、结论

1. DINOv3 ConvNeXt 可作为冻结特征提取器，在保持稳定性的同时具备较强的语义泛化能力。
2. 输出步长 (OS) 是决定 PSPNet 有效性的关键因素。当 OS 过大时，PPM 的效果受限。
3. FPN 有效解决了 DINOv3 的分辨率瓶颈，恢复了多尺度信息，显著提升语义分割性能。
4. 提高 FPN 输出通道数可以提高模型性能
5. 最终模型 DINOv3 + FPN + PPM + 分类头（1024通道） 在 PASCAL VOC 上取得 mIoU 0.8162，相较原 PSPNet 提升约 5.9%，验证了融合方案的有效性。
